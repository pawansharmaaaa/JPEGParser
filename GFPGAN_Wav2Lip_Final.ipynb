{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "eFbemEAJhui2",
        "IPqP6ZzJ_ueK"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pawansharmaaaa/JPEGParser/blob/main/GFPGAN_Wav2Lip_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prerequisites"
      ],
      "metadata": {
        "id": "6QPH1UIrzkRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialization"
      ],
      "metadata": {
        "id": "xnHM2wvud_g9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qciH4PsUazL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9825d47-b240-45af-d382-7416a9383e52"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/Data"
      ],
      "metadata": {
        "id": "M3cShHJ9nTb_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -ri \"/content/drive/MyDrive/Wav2Lip_Mod/TAudio.wav\" \"/content/drive/MyDrive/Wav2Lip_Mod/input_vid.mp4\" /content/Data"
      ],
      "metadata": {
        "id": "fuLbKrST5etk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wav2Lip"
      ],
      "metadata": {
        "id": "rgOmJn0-eD4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pawansharmaaaa/Wav2Lip_Mod.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlOPNDG-f6n9",
        "outputId": "f7455796-42f9-4905-fc07-5781695360b3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Wav2Lip_Mod'...\n",
            "remote: Enumerating objects: 399, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 399 (delta 19), reused 1 (delta 0), pack-reused 360\u001b[K\n",
            "Receiving objects: 100% (399/399), 551.75 KiB | 16.23 MiB/s, done.\n",
            "Resolving deltas: 100% (217/217), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -ri \"/content/drive/MyDrive/Wav2Lip_Mod/wav2lip.pth\" \"/content/drive/MyDrive/Wav2Lip_Mod/wav2lip_gan.pth\" /content/Wav2Lip_Mod/checkpoints"
      ],
      "metadata": {
        "id": "q-TvJSOOgDuN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooh28vw-Uvd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53817fd0-4a21-45f6-cfe7-35a29e6c48ec"
      },
      "source": [
        "!pip uninstall tensorflow tensorflow-gpu\n",
        "!cd Wav2Lip_Mod && pip install -r requirements.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.12.0\n",
            "Uninstalling tensorflow-2.12.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow-2.12.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting librosa==0.9.1 (from -r requirements.txt (line 1))\n",
            "  Downloading librosa-0.9.1-py3-none-any.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.1/213.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.22.4)\n",
            "Requirement already satisfied: opencv-contrib-python>=4.2.0.34 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.7.0.72)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.7.0.72)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.45.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.65.0)\n",
            "Requirement already satisfied: numba>=0.48 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.56.4)\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (19.24.2)\n",
            "Collecting face_recognition (from -r requirements.txt (line 10))\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting gfpgan (from -r requirements.txt (line 11))\n",
            "  Downloading gfpgan-1.3.8-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting realesrgan (from -r requirements.txt (line 12))\n",
            "  Downloading realesrgan-0.3.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: audioread>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (4.4.2)\n",
            "Collecting resampy>=0.2.2 (from librosa==0.9.1->-r requirements.txt (line 1))\n",
            "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->-r requirements.txt (line 5)) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->-r requirements.txt (line 5)) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->-r requirements.txt (line 5)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->-r requirements.txt (line 5)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->-r requirements.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->-r requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.1.0->-r requirements.txt (line 5)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.1.0->-r requirements.txt (line 5)) (16.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.3.0->-r requirements.txt (line 6)) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.3.0->-r requirements.txt (line 6)) (8.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.48->-r requirements.txt (line 8)) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.48->-r requirements.txt (line 8)) (67.7.2)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition->-r requirements.txt (line 10))\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition->-r requirements.txt (line 10)) (8.1.6)\n",
            "Collecting basicsr>=1.4.2 (from gfpgan->-r requirements.txt (line 11))\n",
            "  Downloading basicsr-1.4.2.tar.gz (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting facexlib>=0.2.5 (from gfpgan->-r requirements.txt (line 11))\n",
            "  Downloading facexlib-0.3.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lmdb (from gfpgan->-r requirements.txt (line 11))\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gfpgan->-r requirements.txt (line 11)) (6.0.1)\n",
            "Collecting tb-nightly (from gfpgan->-r requirements.txt (line 11))\n",
            "  Downloading tb_nightly-2.14.0a20230721-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yapf (from gfpgan->-r requirements.txt (line 11))\n",
            "  Downloading yapf-0.40.1-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.3/250.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from basicsr>=1.4.2->gfpgan->-r requirements.txt (line 11))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->gfpgan->-r requirements.txt (line 11)) (0.18.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->gfpgan->-r requirements.txt (line 11)) (0.19.3)\n",
            "Collecting filterpy (from facexlib>=0.2.5->gfpgan->-r requirements.txt (line 11))\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 1)) (1.4.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.3.0->-r requirements.txt (line 6)) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.3.0->-r requirements.txt (line 6)) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.3.0->-r requirements.txt (line 6)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.3.0->-r requirements.txt (line 6)) (3.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->librosa==0.9.1->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.10.2->librosa==0.9.1->-r requirements.txt (line 1)) (1.15.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->-r requirements.txt (line 5)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan->-r requirements.txt (line 11)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan->-r requirements.txt (line 11)) (1.56.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan->-r requirements.txt (line 11)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan->-r requirements.txt (line 11)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan->-r requirements.txt (line 11)) (3.4.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan->-r requirements.txt (line 11)) (3.20.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan->-r requirements.txt (line 11)) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan->-r requirements.txt (line 11)) (2.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan->-r requirements.txt (line 11)) (0.40.0)\n",
            "Collecting importlib-metadata>=6.6.0 (from yapf->gfpgan->-r requirements.txt (line 11))\n",
            "  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->gfpgan->-r requirements.txt (line 11)) (3.9.1)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->gfpgan->-r requirements.txt (line 11)) (2.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.1->-r requirements.txt (line 1)) (2.21)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->gfpgan->-r requirements.txt (line 11)) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->gfpgan->-r requirements.txt (line 11)) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->gfpgan->-r requirements.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->gfpgan->-r requirements.txt (line 11)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tb-nightly->gfpgan->-r requirements.txt (line 11)) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->gfpgan->-r requirements.txt (line 11)) (3.16.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from filterpy->facexlib>=0.2.5->gfpgan->-r requirements.txt (line 11)) (3.7.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->gfpgan->-r requirements.txt (line 11)) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->gfpgan->-r requirements.txt (line 11)) (2023.7.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->gfpgan->-r requirements.txt (line 11)) (1.4.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly->gfpgan->-r requirements.txt (line 11)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tb-nightly->gfpgan->-r requirements.txt (line 11)) (3.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->gfpgan->-r requirements.txt (line 11)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->gfpgan->-r requirements.txt (line 11)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->gfpgan->-r requirements.txt (line 11)) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->gfpgan->-r requirements.txt (line 11)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->gfpgan->-r requirements.txt (line 11)) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->gfpgan->-r requirements.txt (line 11)) (2.8.2)\n",
            "Building wheels for collected packages: basicsr, face-recognition-models, filterpy\n",
            "  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for basicsr: filename=basicsr-1.4.2-py3-none-any.whl size=214824 sha256=2e3554d0f9f45ffa75ee85f11a550b593d9b28bc8275dd5a45a96fa7ac44fbb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/83/99/2d8437cc652a01af27df5ff037a4075e95b52d67705c5f30ca\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566173 sha256=2ecbb29af4bda52ecd436fff8fef41683bd2e72b60e6c30f4aba70eb4e1ea783\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110459 sha256=2e431f508ef35fd2da6ebf188d1354f4ad1d8a4ff2bab3b94ae89ccf74fb86d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/0c/ea/218f266af4ad626897562199fbbcba521b8497303200186102\n",
            "Successfully built basicsr face-recognition-models filterpy\n",
            "Installing collected packages: lmdb, face-recognition-models, addict, importlib-metadata, face_recognition, yapf, resampy, librosa, filterpy, tb-nightly, facexlib, basicsr, gfpgan, realesrgan\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.6.4\n",
            "    Uninstalling importlib-metadata-4.6.4:\n",
            "      Successfully uninstalled importlib-metadata-4.6.4\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.10.0.post2\n",
            "    Uninstalling librosa-0.10.0.post2:\n",
            "      Successfully uninstalled librosa-0.10.0.post2\n",
            "Successfully installed addict-2.4.0 basicsr-1.4.2 face-recognition-models-0.3.0 face_recognition-1.3.0 facexlib-0.3.0 filterpy-1.4.5 gfpgan-1.3.8 importlib-metadata-6.8.0 librosa-0.9.1 lmdb-1.4.1 realesrgan-0.3.0 resampy-0.4.2 tb-nightly-2.14.0a20230721 yapf-0.40.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"Wav2Lip_Mod/face_detection/detection/sfd/s3fd.pth\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Gp5rgX2gily",
        "outputId": "5c0ac10e-8d76-4467-b35c-091983a46bcd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-21 22:07:13--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n",
            "Resolving www.adrianbulat.com (www.adrianbulat.com)... 45.136.29.207\n",
            "Connecting to www.adrianbulat.com (www.adrianbulat.com)|45.136.29.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89843225 (86M) [application/octet-stream]\n",
            "Saving to: ‘Wav2Lip_Mod/face_detection/detection/sfd/s3fd.pth’\n",
            "\n",
            "Wav2Lip_Mod/face_de 100%[===================>]  85.68M  13.4MB/s    in 7.6s    \n",
            "\n",
            "2023-07-21 22:07:22 (11.3 MB/s) - ‘Wav2Lip_Mod/face_detection/detection/sfd/s3fd.pth’ saved [89843225/89843225]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GFPGAN"
      ],
      "metadata": {
        "id": "Wg1Q8kdid7fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd Wav2Lip_Mod && git clone https://github.com/TencentARC/GFPGAN.git"
      ],
      "metadata": {
        "id": "TDLmcaR7znD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install basicsr facexlib"
      ],
      "metadata": {
        "id": "6bkAWnWSzuD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd Wav2Lip_Mod/GFPGAN && pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "F193o3k9z6ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd Wav2Lip_Mod/GFPGAN && python setup.py develop"
      ],
      "metadata": {
        "id": "lksYC-4N1iqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install realesrgan"
      ],
      "metadata": {
        "id": "TOyZ7DAN0Ht8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd Wav2Lip_Mod/GFPGAN && wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P experiments/pretrained_models"
      ],
      "metadata": {
        "id": "N9z8IvMm0MPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd Wav2Lip_Mod/GFPGAN && python inference_gfpgan.py -i /content/GFPGAN/inputs/test2.jpg -o results/new -v 1.3 -s 2"
      ],
      "metadata": {
        "id": "MQclq04B0WFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gfpgan"
      ],
      "metadata": {
        "id": "1ZBKqSViD5_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -ri \"/content/Data/w2l_input_video.mp4\" /content/drive/MyDrive/Finalized_notebook"
      ],
      "metadata": {
        "id": "ONBjxcJX5PY9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*Remove Frames Which do not contain faces from the Video*"
      ],
      "metadata": {
        "id": "eFbemEAJhui2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import face_recognition\n",
        "import gc\n",
        "import tqdm\n",
        "\n",
        "# Function to detect face in a frame\n",
        "def detect_face(frames):\n",
        "    batch_face_locations = face_recognition.batch_face_locations(frames, number_of_times_to_upsample=0)\n",
        "    return batch_face_locations\n",
        "\n",
        "# Open the video file for reading\n",
        "video_path = '/content/Data/linus.mp4'\n",
        "video_capture = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get video properties\n",
        "fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
        "frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Create video writers for face.mp4\n",
        "face_writer = cv2.VideoWriter('/content/Data/w2l_input_video.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
        "\n",
        "batch_size = 16\n",
        "frames = []\n",
        "while True:\n",
        "    ret, frame = video_capture.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Detect faces in the frame\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    frames.append(frame)\n",
        "\n",
        "    if len(frames) == batch_size:\n",
        "      batch_faces = detect_face(frames)\n",
        "\n",
        "      for frame_no, face_locations in enumerate(tqdm.tqdm(batch_faces, total=batch_size)):\n",
        "        if len(face_locations) == 1:\n",
        "            # Write the frame to input_video.mp4 if a face is detected\n",
        "            pos_frame = cv2.cvtColor(frames[frame_no], cv2.COLOR_RGB2BGR)\n",
        "            face_writer.write(pos_frame)\n",
        "      frames = []\n",
        "\n",
        "# Release video capture, writers and clear garbage\n",
        "video_capture.release()\n",
        "face_writer.release()\n",
        "cv2.destroyAllWindows()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "c2WqC9RbJvU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Running Wav2Lip"
      ],
      "metadata": {
        "id": "fT0FwwmPnltV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd Wav2Lip_Mod && python inference_wgan.py --checkpoint_path checkpoints/wav2lip.pth --face \"/content/Data/w2l_input_video.mp4\" --audio \"/content/Data/TAudio.wav\" --resize_factor 2 --upscale --nosmooth"
      ],
      "metadata": {
        "id": "E_av1IIc4PWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FRAMER.py"
      ],
      "metadata": {
        "id": "IPqP6ZzJ_ueK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/GFPGAN')\n",
        "!cd GFPGAN"
      ],
      "metadata": {
        "id": "-UV6K6eTFhOW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd GFPGAN\n",
        "import cv2\n",
        "import os\n",
        "from gfpgan import GFPGANer\n",
        "import torch\n",
        "\n",
        "\n",
        "def divide_video_into_frames(video_path, output_dir):\n",
        "    #LOAD REALESRGAN\n",
        "    upsample_bg = 'realesrgan'\n",
        "    if upsample_bg == 'realesrgan':\n",
        "        if not torch.cuda.is_available():  # CPU\n",
        "            import warnings\n",
        "            warnings.warn('The unoptimized RealESRGAN is slow on CPU. We do not use it. '\n",
        "                          'If you really want to use it, please modify the corresponding codes.')\n",
        "            bg_upsampler = None\n",
        "        else:\n",
        "            from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "            from realesrgan import RealESRGANer\n",
        "            model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=2)\n",
        "            bg_upsampler = RealESRGANer(\n",
        "                scale=2,\n",
        "                model_path='https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.1/RealESRGAN_x2plus.pth',\n",
        "                model=model,\n",
        "                tile=0,\n",
        "                tile_pad=10,\n",
        "                pre_pad=0,\n",
        "                half=True)  # need to set False in CPU mode\n",
        "    else:\n",
        "        bg_upsampler = None\n",
        "\n",
        "    #LOAD GFPGAN\n",
        "    arch = 'clean'\n",
        "    channel_multiplier = 2\n",
        "    model_name = 'GFPGANv1.3'\n",
        "    url = 'https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth'\n",
        "\n",
        "    restorer = GFPGANer(\n",
        "        model_path=url,\n",
        "        upscale=2,\n",
        "        arch=arch,\n",
        "        channel_multiplier=channel_multiplier,\n",
        "        bg_upsampler=bg_upsampler)\n",
        "\n",
        "    # Get the video capture object\n",
        "    video_capture = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Get the number of frames in the video\n",
        "    num_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    print(f\"Frames to improve: {num_frames}\")\n",
        "\n",
        "    # Iterate over the frames in the video\n",
        "    for i in range(num_frames):\n",
        "        # Read the frame from the video\n",
        "        success, frame = video_capture.read()\n",
        "\n",
        "        # If the frame was read successfully, save it\n",
        "        if success:\n",
        "            frame_name = os.path.join(output_dir, str(i) + \".jpg\")\n",
        "            cropped_faces, restored_faces, restored_img = restorer.enhance(\n",
        "              frame,\n",
        "              has_aligned=False,\n",
        "              only_center_face=False,\n",
        "              paste_back=True,\n",
        "              weight=0.5)\n",
        "\n",
        "            cv2.imwrite(frame_name, restored_img)\n",
        "\n",
        "    # Close the video capture object\n",
        "    video_capture.release()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set the video path and output directory\n",
        "    video_path = \"/content/result_voice_theek.mp4\"\n",
        "    output_dir = \"/content/Frames\"\n",
        "\n",
        "    # Divide the video into frames\n",
        "    divide_video_into_frames(video_path, output_dir)"
      ],
      "metadata": {
        "id": "YF6L-bst_tz4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}